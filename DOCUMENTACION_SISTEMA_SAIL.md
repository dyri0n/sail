# üìÑ Documentaci√≥n T√©cnica Extendida: Proyecto SAIL

## üöÄ 1. Arquitectura de Datos y Flujos de Informaci√≥n
**SAIL** emplea un enfoque de **Data-as-Infrastructure**, donde cada componente es agn√≥stico pero est√° fuertemente integrado mediante Docker.

### üìÅ Pipeline de Ingesta (ELT vs ETL)
A diferencia de un ETL tradicional, SAIL aplica un enfoque h√≠brido:
1.  **Extract & Load (EL) / Staging**: Los Workers Python extraen archivos Excel/CSV y los cargan en `stg` "as-is" usando `Pandas` (con tipos de datos flexibles).
2.  **Transform (T) / Loading**: La l√≥gica de negocio pesada reside en PostgreSQL mediante scripts SQL, aprovechando el motor de base de datos para join y agregaciones masivas.

---

## üèóÔ∏è 2. Deep Dive: Motor de Base de Datos (PostgreSQL 17)
### A. Segregaci√≥n de Roles y Seguridad (RBAC)
El sistema implementa una pol√≠tica de privilegios m√≠nimos:
-   **`dwh_admin`**: Propietario del schema `dwh`. Tiene permisos de `SELECT` sobre `stg`. Es el usuario utilizado por Airflow para las transformaciones finales.
-   **`stg_admin`**: Propietario del schema `stg`. √önico usuario con permisos de `TRUNCATE` y `INSERT` sobre tablas temporales.
-   **Superusuario (`postgres`)**: Reservado para tareas de mantenimiento e inicializaci√≥n.

### B. Gesti√≥n de Integridad en Cargas Masivas
Para optimizar el rendimiento de los DAGs de "Poblado Completo", se implementa un patr√≥n de **Desactivaci√≥n de Triggers**:
```sql
ALTER TABLE dwh.fact_rotacion DISABLE TRIGGER ALL;
-- Proceso de carga masiva
ALTER TABLE dwh.fact_rotacion ENABLE TRIGGER ALL;
```
Esto permite realizar inserciones de millones de registros sin la sobrecarga de validaci√≥n inmediata de Foreign Keys, la cual se valida al reactivar o mediante procesos de auditor√≠a post-carga.

---

## üîÑ 3. L√≥gica de Transformaci√≥n Advanced: SCD Tipo 2
La dimensi√≥n `dim_empleado` es el coraz√≥n anal√≠tico y utiliza **Slowly Changing Dimensions (SCD) Tipo 2** para mantener la trazabilidad hist√≥rica.

### Mecanismo de Detecci√≥n de Cambios (Hashing)
En lugar de comparar columna por columna, el sistema genera un hash MD5 de los atributos personales:
```sql
MD5(ROW(s.nombre, s.sexo, s.fecha_nacimiento, s.nacionalidad, s.estado_civil)::text)
```
Si el hash de Staging difiere del hash de la fila activa en DWH, el sistema:
1.  **Cierra** la versi√≥n actual (`scd_es_actual = FALSE`, `fecha_fin = Ayer`).
2.  **Inserta** una nueva fila con los datos actualizados y `scd_es_actual = TRUE`.

### Clasificaci√≥n de Acciones (Logic Engine)
El script de transformaci√≥n utiliza un CTE o tabla temporal para clasificar cada registro de origen en etiquetas: `NUEVO`, `REACTIVAR_SCD1`, `REINGRESO_SCD2`, `BAJA_SCD2`, `CAMBIO_SCD2`, facilitando el mantenimiento y debugging de la l√≥gica.

---

## üå¨Ô∏è 4. Orquestaci√≥n Avanzada con Airflow 3.x
### A. Patr√≥n TaskFlow API
El sistema utiliza el decorador `@task` (TaskFlow API) en lugar de los operadores tradicionales para las tareas de Python, lo que permite el paso de objetos y metadatos (XComs) de forma nativa y tipada.

### B. Aislamiento de Ejecuci√≥n (DockerOperator)
Las tareas que requieren dependencias espec√≠ficas de Python o gran c√≥mputo se ejecutan mediante contenedores ef√≠meros. Esto garantiza que el core de Airflow no se vea afectado por conflictos de librer√≠as o fugas de memoria durante el procesamiento de Excels pesados.

---

## üåê 5. Infraestructura y Red (Networking)
### Comunicaci√≥n Inter-Contenedor
Debido a que los servicios residen en diferentes `docker-compose.yaml`, el sistema utiliza el host bridge o redes compartidas:
-   **Host Aliasing**: Se utiliza `host.docker.internal` para que el nodo ETL pueda alcanzar al DWH independientemente de si la IP local cambia.
-   **Persistence**: El volumen `pg_data` utiliza un driver local mapeado para asegurar que los datos del DWH sobrevivan a reinicios de contenedores o actualizaciones de imagen.

---

## üìà 6. Patrones de Dise√±o ETL
1.  **Idempotencia**: Todos los scripts SQL est√°n dise√±ados para ser ejecutados m√∫ltiples veces sin duplicar datos (uso de `UPSERT` o clasificaci√≥n previa).
2.  **Truncate-and-Load**: La zona de `stg` se limpia en cada inicio de ciclo para garantizar que no existan datos zombies de ejecuciones fallidas.
3.  **Audit Columns**: Cada tabla de hechos y dimensiones cuenta con `fecha_carga` para trazabilidad de linaje de datos.

---

## üìù 7. Especificaciones T√©cnicas de Software
- **Python**: 3.11 (Optimizado para Pandas 2.x)
- **PostgreSQL**: 17.x (Aprovechando `MERGE` statement nativo)
- **Airflow**: 3.x (Utilizando el nuevo scheduler de alta disponibilidad)
- **OS Base**: Debian Bullseye (en im√°genes Docker por estabilidad)
