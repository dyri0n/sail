# =============================================================================
# CONFIGURACIÓN DE ENTORNO - AIRFLOW ETL NODE
# =============================================================================
# Copia este archivo a .env y ajusta los valores según tu entorno.
# NUNCA commitees el archivo .env con credenciales reales.
#
# USO:
#   1. Copia: cp .env.example .env
#   2. Ajusta valores según tu entorno (testing local o producción remota)
#   3. Las variables se inyectan automáticamente en docker-compose.yaml
#   4. Airflow-init las usa para crear conexiones automáticamente
# =============================================================================

# =============================================================================
# SECCIÓN 1: CREDENCIALES ADMIN DE AIRFLOW
# =============================================================================
# Usuario y contraseña para acceder a la UI de Airflow (http://localhost:8080)
# El servicio 'airflow-init' crea este usuario automáticamente al iniciar.
# -----------------------------------------------------------------------------

# Generar una clave Fernet para encriptar conexiones:
# Usa el script de Python: ./scripts/generate_fernet_key
AIRFLOW_FERNET_KEY="clave no muy segura"

AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_FIRSTNAME=Admin
AIRFLOW_ADMIN_LASTNAME=User
AIRFLOW_ADMIN_EMAIL=admin@ejemplo.cl

# UID del usuario airflow dentro del contenedor (permisos de archivos)
AIRFLOW_UID=50000

# =============================================================================
# SECCIÓN 2: DATA WAREHOUSE (DWH) - BASE DE DATOS PRODUCCIÓN
# =============================================================================
# El DWH almacena las tablas dimensionales y de hechos (modelo Kimball).
# Los DAGs de Airflow ejecutan transformaciones SQL en esta base.
#
# CUÁNDO USAR CADA HOST:
#   - host.docker.internal: Desde contenedor Airflow hacia host Windows/Mac
#   - localhost: Desde tu máquina (fuera de Docker) hacia el contenedor DWH
#   - dwh_rrhh_container: Si DWH y Airflow están en la misma red Docker
#
# TESTING LOCAL (dwh-node levantado en mismo host):
#   DWH_HOST=host.docker.internal
#   DWH_PORT=6000
#
# PRODUCCIÓN (DWH en servidor remoto):
#   DWH_HOST=192.168.1.50
#   DWH_PORT=6000
# -----------------------------------------------------------------------------
DWH_HOST=host.docker.internal
DWH_PORT=6000
DWH_USER=dwh_admin
DWH_PASSWORD=sail-rrhh-p4
DWH_DATABASE=rrhh_prod

# --- MODO MOCK LOCAL: DWH simulado para testear compilación ---
# DWH_HOST=mock-dwh
# DWH_PORT=5432
# DWH_USER=test_user
# DWH_PASSWORD=test_password
# DWH_DATABASE=test_dwh

# =============================================================================
# SECCIÓN 3: AIRFLOW CONNECTIONS (IDs de conexión internos)
# =============================================================================
# Nombres de las conexiones que Airflow crea automáticamente en la UI.
# Puedes referenciarlos en tus DAGs con: PostgresHook(postgres_conn_id='...')
# No cambies estos IDs a menos que sepas lo que haces.
# -----------------------------------------------------------------------------
AIRFLOW_DWH_CONN_ID=dwh_postgres_conn

# =============================================================================
# SECCIÓN 4: ETL WORKERS - CONTENEDORES REMOTOS PARA PROCESAMIENTO PESADO
# =============================================================================
# Cuando un DAG necesita ejecutar Python pesado (lecturas de Excel, pandas),
# puede lanzar contenedores efímeros usando DockerOperator.
# Estos contenedores se ejecutan fuera de Airflow y se destruyen al terminar.
#
# TESTING LOCAL:
#   DOCKER_WORKER_URL=unix://var/run/docker.sock  (mismo host)
#
# PRODUCCIÓN (worker remoto):
#   DOCKER_WORKER_URL=tcp://192.168.1.60:2375
# -----------------------------------------------------------------------------
ETL_WORKER_IMAGE=mi-sistema/etl-worker:latest
DOCKER_WORKER_URL=unix://var/run/docker.sock
DOCKER_NETWORK_MODE=bridge

# Límites de recursos para cada contenedor worker
WORKER_MEM_LIMIT=2g
WORKER_CPUS=1.0

# =============================================================================
# SECCIÓN 5: RUTAS DE DATOS (Volúmenes montados en workers)
# =============================================================================
# Los workers necesitan acceder a archivos de entrada (Excel, CSV).
# Estas rutas mapean directorios del host a directorios dentro del contenedor.
#
# TESTING LOCAL (Windows):
#   DATA_MOUNT_SOURCE=D:/Code/SAIL/etl-node/input_data
#
# PRODUCCIÓN (Linux):
#   DATA_MOUNT_SOURCE=/var/etl/input_data
# -----------------------------------------------------------------------------
DATA_MOUNT_SOURCE=/tmp/etl_data
DATA_MOUNT_TARGET=/app/data
