# üå¨Ô∏è Airflow: El Cerebro del ETL

Apache Airflow **3.x** orquesta todos los flujos de trabajo del Data Warehouse. Esta versi√≥n utiliza el nuevo `LocalExecutor` y el componente `DAG Processor` separado.

## üìÅ Estructura

```
airflow/
‚îú‚îÄ‚îÄ docker-compose.yaml       # Stack completo Airflow 3.x
‚îú‚îÄ‚îÄ Dockerfile                # Imagen con providers instalados
‚îú‚îÄ‚îÄ pyproject.toml            # Configuraci√≥n proyecto Python
‚îú‚îÄ‚îÄ requirements-dev.txt      # Dependencias desarrollo
‚îú‚îÄ‚îÄ .env.example              # ‚ö†Ô∏è COPIAR A .env
‚îÇ
‚îú‚îÄ‚îÄ dags/                     # Flujos de trabajo
‚îÇ   ‚îú‚îÄ‚îÄ dag_conformed.py      # DAG 01: Carga dimensiones
‚îÇ   ‚îú‚îÄ‚îÄ dag_rotacion.py       # DAG 02: Carga facts rotaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ example_dag.py        # Ejemplo de referencia
‚îÇ   ‚îú‚îÄ‚îÄ trigger_etl.py        # Trigger manual
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py       # Configuraci√≥n centralizada
‚îÇ   ‚îî‚îÄ‚îÄ sql/
‚îÇ       ‚îú‚îÄ‚îÄ dimensiones/      # Scripts SQL para dims
‚îÇ       ‚îî‚îÄ‚îÄ fact-tables/      # Scripts SQL para facts
‚îÇ
‚îú‚îÄ‚îÄ logs/                     # Logs de ejecuci√≥n (auto-generado)
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ compose-up.ps1        # Levantar (Windows)
    ‚îú‚îÄ‚îÄ compose-up.sh         # Levantar (Linux/Mac)
    ‚îú‚îÄ‚îÄ compose-down.ps1      # Detener (Windows)
    ‚îú‚îÄ‚îÄ compose-down.sh       # Detener (Linux/Mac)
    ‚îú‚îÄ‚îÄ generate-fernet-key.ps1  # Generar Fernet Key (Windows)
    ‚îî‚îÄ‚îÄ generate-fernet-key.sh   # Generar Fernet Key (Linux/Mac)
```

## ‚öôÔ∏è Configuraci√≥n de Variables de Entorno

### Paso 1: Copiar archivo de ejemplo

```powershell
cp .env.example .env
```

### Paso 2: Configurar `.env`

El archivo `.env.example` contiene todas las variables documentadas. Las m√°s importantes son:

#### üîê Credenciales Airflow

```dotenv
# Usuario admin para UI (http://localhost:8080)
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin            # ‚ö†Ô∏è Cambiar en producci√≥n

# Clave Fernet para encriptar conexiones (OBLIGATORIO cambiar)
AIRFLOW_FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=

# UID del usuario dentro del contenedor
AIRFLOW_UID=50000
```

#### üóÑÔ∏è Conexi√≥n al DWH

```dotenv
# Para desarrollo local (DWH en mismo host)
DWH_HOST=host.docker.internal
DWH_PORT=6000

# Para producci√≥n (DWH en servidor remoto)
# DWH_HOST=192.168.1.50
# DWH_PORT=6000

DWH_USER=dwh_admin
DWH_PASSWORD=sail-rrhh-p4
DWH_DATABASE=rrhh_prod
```

### Paso 3: Generar Fernet Key (Seguridad)

```powershell
# Windows
.\scripts\generate-fernet-key.ps1

# Linux/Mac
./scripts/generate-fernet-key.sh

# O manualmente con Python
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

Copia la clave generada a `AIRFLOW_FERNET_KEY` en tu `.env`.

## üöÄ Levantar Servicios

```powershell
# Windows
.\scripts\compose-up.ps1

# Linux/Mac
./scripts/compose-up.sh

# O directamente
docker compose up -d
```

### Servicios que se levantan:

| Servicio                | Puerto | Descripci√≥n                   |
| ----------------------- | ------ | ----------------------------- |
| `airflow-webserver`     | 8080   | UI web (API Server)           |
| `airflow-scheduler`     | -      | Programa tareas               |
| `airflow-dag-processor` | -      | Parsea DAGs (nuevo en 3.x)    |
| `airflow-init`          | -      | Inicializa BD y usuario admin |
| `postgres`              | -      | Metadatos de Airflow          |

### Verificar estado

```powershell
# Ver contenedores
docker compose ps

# Logs del scheduler
docker compose logs airflow-scheduler -f

# Logs de inicializaci√≥n
docker compose logs airflow-init
```

## üîÑ DAGs Disponibles

### DAG 01: `01_carga_dimensiones_conformadas`

Carga todas las dimensiones maestras del DWH.

**Flujo:**

```
inicio_carga
    ‚îú‚îÄ‚îÄ> dim_tiempo (paralelo)
    ‚îú‚îÄ‚îÄ> dim_cargo (paralelo)
    ‚îú‚îÄ‚îÄ> dim_empresa (paralelo)
    ‚îú‚îÄ‚îÄ> dim_gerencia (paralelo)
    ‚îú‚îÄ‚îÄ> dim_centro_costo (paralelo)
    ‚îî‚îÄ‚îÄ> dim_modalidad (paralelo)
              ‚îÇ
              ‚ñº
         dim_empleado (SCD Tipo 2)
              ‚îÇ
              ‚ñº
         fin_carga
```

**Schedule:** `@daily`

### DAG 02: `02_carga_hechos_movimientos_dotacion`

Carga las tablas de hechos de rotaci√≥n y dotaci√≥n.

**Flujo:**

```
inicio_facts
    ‚îÇ
    ‚ñº
dim_medida
    ‚îÇ
    ‚ñº
fact_rotacion_transaccional
    ‚îÇ
    ‚ñº
fact_dotacion_snapshot
    ‚îÇ
    ‚ñº
fin_facts
```

**Schedule:** `@daily`

## üîå Conexiones Configuradas

El servicio `airflow-init` crea autom√°ticamente estas conexiones:

| Connection ID       | Tipo     | Host        | Puerto      | Schema          |
| ------------------- | -------- | ----------- | ----------- | --------------- |
| `dwh_postgres_conn` | Postgres | `$DWH_HOST` | `$DWH_PORT` | `$DWH_DATABASE` |

Para verificar o editar:

```bash
# Listar conexiones
docker exec airflow-scheduler airflow connections list

# Ver detalles
docker exec airflow-scheduler airflow connections get dwh_postgres_conn
```

## üìù Archivos SQL

Los scripts SQL de transformaci√≥n est√°n en `dags/sql/`:

### Dimensiones (`sql/dimensiones/`)

| Archivo                      | Tabla Destino                | Descripci√≥n                      |
| ---------------------------- | ---------------------------- | -------------------------------- |
| `poblar_dim_tiempo.sql`      | `dwh.dim_tiempo`             | Genera calendario 2010-2028      |
| `update_feriados.sql`        | `dwh.dim_tiempo`             | Actualiza feriados desde staging |
| `dim_cargo.sql`              | `dwh.dim_cargo`              | MERGE cargos                     |
| `dim_empresa.sql`            | `dwh.dim_empresa`            | MERGE empresas                   |
| `dim_gerencia.sql`           | `dwh.dim_gerencia`           | MERGE gerencias                  |
| `dim_centro_costo.sql`       | `dwh.dim_centro_costo`       | MERGE centros de costo           |
| `dim_modalidad_contrato.sql` | `dwh.dim_modalidad_contrato` | MERGE modalidades                |
| `merge_dim_empleado.sql`     | `dwh.dim_empleado`           | SCD Tipo 2 empleados             |

### Tablas de Hechos (`sql/fact-tables/`)

| Archivo             | Tabla Destino       | Descripci√≥n                |
| ------------------- | ------------------- | -------------------------- |
| `fact_rotacion.sql` | `dwh.fact_rotacion` | Movimientos de personal    |
| `fact_dotacion.sql` | `dwh.fact_dotacion` | Snapshot mensual headcount |

## üß™ Testing

### Ejecutar DAG manualmente

```bash
# Desde el host
docker exec airflow-scheduler airflow dags trigger 01_carga_dimensiones_conformadas

# Con par√°metros
docker exec airflow-scheduler airflow dags trigger 01_carga_dimensiones_conformadas --conf '{"param1": "valor"}'
```

### Probar una tarea espec√≠fica

```bash
docker exec airflow-scheduler airflow tasks test 01_carga_dimensiones_conformadas merge_dim_tiempo 2024-01-01
```

## üêõ Troubleshooting

### Error: "Connection refused" al DWH

Verifica que `DWH_HOST` est√© correcto en `.env`:

- Windows/Mac: `host.docker.internal`
- Linux: IP del host o nombre del contenedor

### Error: "Invalid Fernet Key"

Regenera la clave:

```powershell
.\scripts\generate-fernet-key.ps1
# Copia la clave a .env y reinicia
docker compose down
docker compose up -d
```

### DAGs no aparecen

Verifica los logs del DAG Processor:

```bash
docker compose logs airflow-dag-processor
```

### Limpiar y reiniciar todo

```powershell
docker compose down -v  # ‚ö†Ô∏è Elimina vol√∫menes
docker compose up -d --build
```
